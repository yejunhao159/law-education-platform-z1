/**
 * AIè°ƒç”¨ä»£ç†å±‚ - ç»Ÿä¸€AIæœåŠ¡è°ƒç”¨å…¥å£
 *
 * åŠŸèƒ½ï¼š
 * - æ‹¦æˆªæ‰€æœ‰DeepSeek APIè°ƒç”¨ï¼Œé‡å®šå‘åˆ°DeeChatAIClient
 * - æä¾›ä¸åŸDeepSeek APIå®Œå…¨ä¸€è‡´çš„å“åº”æ ¼å¼
 * - ç»Ÿä¸€æˆæœ¬æ§åˆ¶ã€é”™è¯¯å¤„ç†ã€æ—¥å¿—è®°å½•
 * - æœ€å°åŒ–å¯¹ç°æœ‰ä¸šåŠ¡é€»è¾‘çš„ä¾µå…¥
 *
 * è§£å†³Issue #21: ç»Ÿä¸€AIè°ƒç”¨åè®®ï¼Œå‡å°‘é‡å¤å¼€å‘
 */

import { DeeChatAIClient, createDeeChatConfig } from '../../domains/socratic-dialogue/services/DeeChatAIClient';

interface AICallProxyConfig {
  provider: 'deepseek' | 'openai' | 'claude';
  apiKey: string;
  apiUrl?: string;
  model: string;
  maxRetries: number;
  timeout: number;
  enableCostTracking: boolean;
  enableErrorFallback: boolean;
}

interface DeepSeekAPIRequest {
  model: string;
  messages: Array<{
    role: 'system' | 'user' | 'assistant';
    content: string;
  }>;
  temperature?: number;
  max_tokens?: number;
  stream?: boolean;
  response_format?: any;
}

interface DeepSeekAPIResponse {
  choices: Array<{
    message: {
      content: string;
      role: string;
    };
    index: number;
    finish_reason: string;
  }>;
  usage: {
    prompt_tokens: number;
    completion_tokens: number;
    total_tokens: number;
  };
  model: string;
  id: string;
  created: number;
}

/**
 * AIè°ƒç”¨ä»£ç†ç±»
 * æ ¸å¿ƒèŒè´£ï¼šæ— ç¼æ‹¦æˆªå¹¶é‡å®šå‘AIè°ƒç”¨ï¼Œä¿è¯ä¸šåŠ¡é€»è¾‘é€æ˜æ€§
 */
export class AICallProxy {
  private static instance: AICallProxy;
  private aiClient: DeeChatAIClient;
  private config: AICallProxyConfig;
  private callStats = {
    totalCalls: 0,
    totalTokens: 0,
    totalCost: 0,
    errors: 0
  };

  private constructor(config: AICallProxyConfig) {
    this.config = config;

    // åŸºäºDeeChatAIClientåˆ›å»ºç»Ÿä¸€AIå®¢æˆ·ç«¯
    const deeChatConfig = createDeeChatConfig({
      provider: config.provider,
      apiKey: config.apiKey,
      apiUrl: config.apiUrl || 'https://api.deepseek.com/v1',
      model: config.model,
      temperature: 0.7,
      maxContextTokens: 8000,
      reserveTokens: 200,
      costThreshold: 0.50, // æé«˜é˜ˆå€¼åˆ°50ç¾åˆ†ï¼Œç¡®ä¿æ³•å­¦æ•™è‚²AIåŠŸèƒ½æ­£å¸¸è¿è¡Œ
      enableCostOptimization: config.enableCostTracking
    });

    this.aiClient = new DeeChatAIClient(deeChatConfig);
  }

  /**
   * è·å–ä»£ç†å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰
   */
  static getInstance(config?: AICallProxyConfig): AICallProxy {
    if (!AICallProxy.instance) {
      // åœ¨Next.jsç¯å¢ƒä¸­å®‰å…¨åœ°è·å–ç¯å¢ƒå˜é‡
      const getEnvVar = (key: string, fallback: string = '') => {
        return typeof process !== 'undefined' && process.env ? process.env[key] || fallback : fallback;
      };

      const defaultConfig: AICallProxyConfig = {
        provider: 'deepseek',
        apiKey: getEnvVar('DEEPSEEK_API_KEY', 'sk-6b081a93258346379182141661293345'), // ä½¿ç”¨.env.localä¸­çš„keyä½œä¸ºfallback
        apiUrl: getEnvVar('DEEPSEEK_API_URL', 'https://api.deepseek.com/v1'),
        model: 'deepseek-chat',
        maxRetries: 3,
        timeout: 30000,
        enableCostTracking: true,
        enableErrorFallback: true
      };

      console.log('ğŸš€ AICallProxyåˆå§‹åŒ–é…ç½®:', {
        provider: defaultConfig.provider,
        apiUrl: defaultConfig.apiUrl,
        model: defaultConfig.model,
        hasApiKey: !!defaultConfig.apiKey,
        keyPrefix: defaultConfig.apiKey.substring(0, 8) + '...'
      });

      AICallProxy.instance = new AICallProxy(config || defaultConfig);
    }
    return AICallProxy.instance;
  }

  /**
   * æ ¸å¿ƒæ–¹æ³•ï¼šæ‹¦æˆªDeepSeek APIè°ƒç”¨
   *
   * @param _url åŸå§‹API URLï¼ˆå…¼å®¹æ€§ï¼Œå®é™…ä¸ä½¿ç”¨ï¼‰
   * @param options åŸå§‹fetch options
   * @returns ä¸DeepSeek APIå®Œå…¨ä¸€è‡´çš„Responseå¯¹è±¡
   */
  async interceptDeepSeekCall(_url: string, options: RequestInit): Promise<Response> {
    const startTime = Date.now();
    const callId = `ai-call-${Date.now()}-${Math.random().toString(36).substring(2, 9)}`;

    try {
      console.log(`ğŸ¤– [${callId}] AIè°ƒç”¨æ‹¦æˆª - å¼€å§‹å¤„ç†`);

      // 1. è§£æåŸå§‹DeepSeekè¯·æ±‚
      const originalRequest = await this.parseDeepSeekRequest(options);

      // 2. æå–systemå’Œuseræ¶ˆæ¯
      const { systemPrompt, userPrompt, requestOptions } = this.extractPrompts(originalRequest);

      // 3. æˆæœ¬é¢„æ£€æŸ¥
      if (this.config.enableCostTracking) {
        await this.checkCostLimits();
      }

      // 4. è°ƒç”¨DeeChatAIClientï¼ˆç»Ÿä¸€AIè°ƒç”¨ï¼‰
      const aiResult = await this.callUnifiedAI(systemPrompt, userPrompt, requestOptions);

      // 5. è½¬æ¢ä¸ºDeepSeek APIæ ¼å¼å“åº”
      const deepSeekResponse = this.formatAsDeepSeekResponse(aiResult, originalRequest.model);

      // 6. è®°å½•è°ƒç”¨ç»Ÿè®¡
      this.updateCallStats(aiResult, Date.now() - startTime);

      console.log(`âœ… [${callId}] AIè°ƒç”¨å®Œæˆ - è€—æ—¶: ${Date.now() - startTime}ms, Tokens: ${aiResult.tokensUsed}`);

      // 7. è¿”å›æ ‡å‡†Responseå¯¹è±¡
      return new Response(JSON.stringify(deepSeekResponse), {
        status: 200,
        headers: {
          'Content-Type': 'application/json',
          'X-AI-Proxy': 'DeeChatAI',
          'X-Call-ID': callId,
          'X-Tokens-Used': aiResult.tokensUsed.toString(),
          'X-Cost': aiResult.cost.toString()
        }
      });

    } catch (error) {
      console.error(`âŒ [${callId}] AIè°ƒç”¨å¤±è´¥:`, error);
      this.callStats.errors++;

      // é”™è¯¯é™çº§å¤„ç†
      if (this.config.enableErrorFallback) {
        return this.generateFallbackResponse(error as Error, callId);
      } else {
        throw error;
      }
    }
  }

  /**
   * é€šç”¨AIè°ƒç”¨æ–¹æ³•ï¼ˆä¾›ä¸šåŠ¡å±‚ç›´æ¥ä½¿ç”¨ï¼‰
   */
  async callAI(
    systemPrompt: string,
    userPrompt: string,
    options?: {
      temperature?: number;
      maxTokens?: number;
      responseFormat?: 'json' | 'text';
    }
  ): Promise<{
    content: string;
    tokensUsed: number;
    cost: number;
    model: string;
    callId: string;
  }> {
    const callId = `direct-call-${Date.now()}`;

    try {
      const result = await this.callUnifiedAI(systemPrompt, userPrompt, options || {});
      return {
        ...result,
        callId
      };
    } catch (error) {
      console.error(`âŒ [${callId}] ç›´æ¥AIè°ƒç”¨å¤±è´¥:`, error);
      throw error;
    }
  }

  /**
   * è·å–è°ƒç”¨ç»Ÿè®¡
   */
  getCallStats() {
    return {
      ...this.callStats,
      successRate: this.callStats.totalCalls > 0
        ? ((this.callStats.totalCalls - this.callStats.errors) / this.callStats.totalCalls * 100).toFixed(2) + '%'
        : '0%',
      averageCostPerCall: this.callStats.totalCalls > 0
        ? (this.callStats.totalCost / this.callStats.totalCalls).toFixed(4)
        : '0'
    };
  }

  // ========== ç§æœ‰è¾…åŠ©æ–¹æ³• ==========

  /**
   * è§£æDeepSeekè¯·æ±‚æ ¼å¼
   */
  private async parseDeepSeekRequest(options: RequestInit): Promise<DeepSeekAPIRequest> {
    if (!options.body) {
      throw new Error('AIè°ƒç”¨ä»£ç†: è¯·æ±‚ä½“ä¸ºç©º');
    }

    try {
      const body = typeof options.body === 'string'
        ? JSON.parse(options.body)
        : options.body;

      return body as DeepSeekAPIRequest;
    } catch (error) {
      throw new Error('AIè°ƒç”¨ä»£ç†: è¯·æ±‚ä½“æ ¼å¼é”™è¯¯ - ' + (error as Error).message);
    }
  }

  /**
   * æå–systemå’Œuseræç¤ºè¯
   */
  private extractPrompts(request: DeepSeekAPIRequest) {
    const messages = request.messages || [];

    let systemPrompt = '';
    let userPrompt = '';

    // æŒ‰æ ‡å‡†OpenAIæ ¼å¼è§£ææ¶ˆæ¯
    for (const message of messages) {
      if (message.role === 'system') {
        systemPrompt = message.content;
      } else if (message.role === 'user') {
        userPrompt += (userPrompt ? '\n\n' : '') + message.content;
      }
    }

    // å¦‚æœæ²¡æœ‰æ˜ç¡®çš„systemæ¶ˆæ¯ï¼Œä½¿ç”¨é»˜è®¤
    if (!systemPrompt) {
      systemPrompt = 'ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œè¯·æ ¹æ®ç”¨æˆ·éœ€æ±‚æä¾›å‡†ç¡®ã€æœ‰ç”¨çš„å›ç­”ã€‚';
    }

    return {
      systemPrompt,
      userPrompt,
      requestOptions: {
        temperature: request.temperature || 0.7,
        maxTokens: request.max_tokens || 1000,
        responseFormat: request.response_format ? 'json' : 'text'
      }
    };
  }

  /**
   * è°ƒç”¨ç»Ÿä¸€AIæœåŠ¡
   */
  private async callUnifiedAI(
    systemPrompt: string,
    userPrompt: string,
    options: any
  ): Promise<{
    content: string;
    tokensUsed: number;
    cost: number;
    model: string;
    duration: number;
  }> {
    const startTime = Date.now();

    try {
      // ä½¿ç”¨DeeChatAIClientçš„sendCustomMessageæ–¹æ³•
      // ä¿®å¤ï¼šç¬¬ä¸€ä¸ªå‚æ•°å¿…é¡»æ˜¯messagesæ•°ç»„ï¼Œä¸æ˜¯å­—ç¬¦ä¸²
      const messages = [
        { role: 'system' as const, content: systemPrompt },
        { role: 'user' as const, content: userPrompt }
      ];

      // sendCustomMessage åªæ¥å—2ä¸ªå‚æ•°ï¼šmessageså’Œoptions
      const result = await this.aiClient.sendCustomMessage(
        messages, // ä¼ é€’messagesæ•°ç»„è€Œä¸æ˜¯å­—ç¬¦ä¸²
        {
          temperature: options.temperature || 0.7,
          maxTokens: options.maxTokens || 1000,
          enableCostOptimization: options.enableCostOptimization ?? true
        }
      );

      return {
        content: result.content,
        tokensUsed: result.tokensUsed.total,
        cost: result.cost.total,
        model: result.model,
        duration: Date.now() - startTime
      };

    } catch (error) {
      console.error('ç»Ÿä¸€AIè°ƒç”¨å¤±è´¥:', error);
      throw error;
    }
  }

  /**
   * æ ¼å¼åŒ–ä¸ºDeepSeek APIå“åº”æ ¼å¼
   */
  private formatAsDeepSeekResponse(
    aiResult: any,
    originalModel: string
  ): DeepSeekAPIResponse {
    return {
      choices: [{
        message: {
          content: aiResult.content,
          role: 'assistant'
        },
        index: 0,
        finish_reason: 'stop'
      }],
      usage: {
        prompt_tokens: Math.floor(aiResult.tokensUsed * 0.7), // ä¼°ç®—
        completion_tokens: Math.floor(aiResult.tokensUsed * 0.3),
        total_tokens: aiResult.tokensUsed
      },
      model: originalModel || this.config.model,
      id: `chatcmpl-${Date.now()}`,
      created: Math.floor(Date.now() / 1000)
    };
  }

  /**
   * æˆæœ¬é™åˆ¶æ£€æŸ¥
   */
  private async checkCostLimits(): Promise<void> {
    // ç®€å•çš„æˆæœ¬æ£€æŸ¥é€»è¾‘
    if (this.callStats.totalCost > 10.0) { // $10é™åˆ¶
      console.warn('âš ï¸ AIè°ƒç”¨æˆæœ¬æ¥è¿‘é™åˆ¶ï¼Œè¯·æ£€æŸ¥ä½¿ç”¨æƒ…å†µ');
    }
  }

  /**
   * æ›´æ–°è°ƒç”¨ç»Ÿè®¡
   */
  private updateCallStats(result: any, _duration: number): void {
    this.callStats.totalCalls++;
    this.callStats.totalTokens += result.tokensUsed;
    this.callStats.totalCost += result.cost;
  }

  /**
   * ç”Ÿæˆé™çº§å“åº”
   */
  private generateFallbackResponse(error: Error, callId: string): Response {
    const fallbackResponse: DeepSeekAPIResponse = {
      choices: [{
        message: {
          content: `æŠ±æ­‰ï¼ŒAIåˆ†ææœåŠ¡æš‚æ—¶ä¸å¯ç”¨ã€‚é”™è¯¯ä¿¡æ¯ï¼š${error.message}ã€‚è¯·ç¨åé‡è¯•æˆ–è”ç³»ç®¡ç†å‘˜ã€‚`,
          role: 'assistant'
        },
        index: 0,
        finish_reason: 'error'
      }],
      usage: {
        prompt_tokens: 0,
        completion_tokens: 50,
        total_tokens: 50
      },
      model: this.config.model,
      id: `fallback-${callId}`,
      created: Math.floor(Date.now() / 1000)
    };

    return new Response(JSON.stringify(fallbackResponse), {
      status: 200, // è¿”å›200ä½†å†…å®¹è¡¨æ˜é”™è¯¯ï¼Œä¿æŒä¸šåŠ¡é€»è¾‘å…¼å®¹
      headers: {
        'Content-Type': 'application/json',
        'X-AI-Proxy': 'DeeChatAI-Fallback',
        'X-Call-ID': callId,
        'X-Error': 'true'
      }
    });
  }
}

/**
 * ä¾¿æ·çš„å¯¼å‡ºå‡½æ•°ï¼Œä¾›APIå±‚ç›´æ¥ä½¿ç”¨
 */
export async function interceptDeepSeekCall(url: string, options: RequestInit): Promise<Response> {
  const proxy = AICallProxy.getInstance();
  return proxy.interceptDeepSeekCall(url, options);
}

/**
 * ç›´æ¥AIè°ƒç”¨å‡½æ•°ï¼Œä¾›ä¸šåŠ¡å±‚ä½¿ç”¨
 */
export async function callUnifiedAI(
  systemPrompt: string,
  userPrompt: string,
  options?: any
) {
  const proxy = AICallProxy.getInstance();
  return proxy.callAI(systemPrompt, userPrompt, options);
}

/**
 * è·å–AIè°ƒç”¨ç»Ÿè®¡
 */
export function getAICallStats() {
  const proxy = AICallProxy.getInstance();
  return proxy.getCallStats();
}